#!/usr/bin/env python3
"""Usage:
  barman-parse-metrics <path>
"""

import docopt
import json
import os
import re
import tempfile

from datetime import datetime, timezone
from dateutil import parser


# These should come from Alex's module code
def parse_timestamp(raw):
    if raw and raw != "None":
        return parser.parse(raw)
    else:
        return None


def seconds_elapsed_since(timestamp):
    if timestamp:
        now = datetime.now()
        return (now - timestamp).total_seconds()
    else:
        return None


def clean_key(k, prefix):
    return prefix + re.sub("[^A-Za-z0-9]", "_", k)


def parse_size(s):
    d = s.split(" ")
    size_name = {"B": 0, "KiB": 10, "MiB": 20, "GiB": 30, "TiB": 40}
    return float(d[0]) * 2**size_name[d[1]]


def parse_last_backup_age(s):
    last_available = parse_timestamp(s)
    if last_available:
        since_last_backup = seconds_elapsed_since(last_available)
        return {
            "barman_time_of_last_backup": last_available.timestamp(),
            "barman_time_since_last_backup_seconds": since_last_backup,
            "barman_time_since_last_backup_minutes": since_last_backup / 60,
            "barman_time_since_last_backup_hours": since_last_backup / 3600,
            "barman_time_since_last_backup_days":
            since_last_backup / (3600 * 24)
        }
    else:
        return {}


def parse_status(path):
    check = barman_output_as_dict(read_lines(path + '/check.txt'))
    status = barman_output_as_dict(read_lines(path + '/status.txt'))
    ret = {clean_key(k, "barman_check_"): int(v.startswith("OK"))
           for (k, v) in check.items()}
    ret["barman_ok"] = all(x == 1 for x in ret.values())
    ret["barman_running"] = True
    ret["barman_data_size"] = parse_size(status["Current data size"])
    ret["barman_pg_version"] = status["PostgreSQL version"]
    ret["barman_available_backups"] = status["No. of available backups"]
    ret.update(parse_last_backup_age(status["Last available backup"]))
    return ret


def save_metrics(data, path):
    now = datetime.now(timezone.utc)
    utc_secs = now.timestamp()
    utc_string = now.isoformat()
    ret = {"utc_secs": utc_secs, "utc_string": utc_string, "data": data}
    dest = path + "/metrics.json"
    # Atomic write
    with tempfile.NamedTemporaryFile(mode='w', dir=path, delete=False) as f:
        f.write(json.dumps(ret))
    os.replace(f.name, dest)


def barman_output_as_dict(text):
    lines = text.split("\n")[1:]
    raw_values = {}
    for line in lines:
        if line:
            k, v = line.split(": ", 1)
            raw_values[k.strip()] = v.strip()
    return raw_values


def read_lines(filename):
    with open(filename, "r") as f:
        return f.read()


if __name__ == "__main__":
    args = docopt.docopt(__doc__)
    path = args['<path>']
    try:
        dat = parse_status(path)
    except:
        dat = {"barman_running": False}
    save_metrics(dat, path)
